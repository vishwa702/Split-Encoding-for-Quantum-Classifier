{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dafef955-4c2c-a871-f1d8-3e0d306393b0"
   },
   "source": [
    "# Using the MNIST data compressed with JPEG method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e26372e-f1bd-b50f-0c1c-33a44306d1f7"
   },
   "source": [
    "#Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 23:29:19.761418: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-29 23:29:19.765838: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 23:29:19.824141: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-29 23:29:19.824170: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-29 23:29:19.824370: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-29 23:29:19.848204: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 23:29:19.849460: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 23:29:20.702063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from pennylane import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images_subsampled.shape:  (60000, 16, 16)\n",
      "test_images_subsampled.shape:  (10000, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "def get_jpeg_data(img, out_length=50):\n",
    "  # Load the image\n",
    "\n",
    "  # Convert the image to YCrCb color space\n",
    "  # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "  # Define the desired size for the subsampled image\n",
    "  new_width = img.shape[0]//2  # Set to half of the original width\n",
    "  new_height = img.shape[1]//2  # Set to half of the original height\n",
    "\n",
    "  # Resize the image to the desired size for subsampling\n",
    "  subsampled_image = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "  # Perform JPEG encoding\n",
    "  retval, buf = cv2.imencode('.jpg', subsampled_image, [cv2.IMWRITE_JPEG_QUALITY, 10])\n",
    "\n",
    "  def find_matching_slice(byte_list, target_slice):\n",
    "      for i in range(len(byte_list) - len(target_slice) + 1):\n",
    "          if byte_list[i:i + len(target_slice)] == target_slice:\n",
    "              return i\n",
    "      return -1\n",
    "\n",
    "  byte_list = buf.tolist()\n",
    "\n",
    "  # Define the start and end sequences to search for\n",
    "  start_sequence = [0xFF, 0xDA]\n",
    "  end_sequence = [0xFF, 0xD9]\n",
    "\n",
    "  # Find the starting and ending indices\n",
    "  start_index = find_matching_slice(byte_list, start_sequence)\n",
    "  end_index = find_matching_slice(byte_list, end_sequence)\n",
    "\n",
    "  # Extract the data between start and end sequences\n",
    "  if start_index != -1 and end_index != -1:\n",
    "      extracted_data = byte_list[start_index + len(start_sequence):end_index]\n",
    "      # Convert the extracted data back to a NumPy array if needed\n",
    "      extracted_data_np = np.array(extracted_data, dtype=np.uint8)\n",
    "\n",
    "      # Pad to fixed size\n",
    "      if extracted_data_np.shape[0] < out_length:\n",
    "        pad_width = out_length - extracted_data_np.shape[0]\n",
    "        extracted_data_np = np.pad(extracted_data_np, (0, pad_width), mode='constant', constant_values=0)\n",
    "      if extracted_data_np.shape[0] > out_length:\n",
    "         extracted_data_np = extracted_data_np[:out_length]\n",
    "      # print(\"Extracted data:\", extracted_data_np)\n",
    "      # print(\"Data Length: \", len(extracted_data_np))\n",
    "  else:\n",
    "      print(\"Start and end sequences not found in the data.\")\n",
    "  return extracted_data_np\n",
    "\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Resize/subsample images \n",
    "sub_dim = 16\n",
    "\n",
    "train_images_subsampled = np.zeros((train_images.shape[0], sub_dim, sub_dim))\n",
    "test_images_subsampled = np.zeros((test_images.shape[0], sub_dim, sub_dim))\n",
    "\n",
    "for i in range(train_images.shape[0]):\n",
    "    train_images_subsampled[i] = cv2.resize(train_images[i], (sub_dim, sub_dim))\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_images_subsampled[i] = cv2.resize(test_images[i], (sub_dim, sub_dim))\n",
    "\n",
    "    \n",
    "print('train_images_subsampled.shape: ', train_images_subsampled.shape)\n",
    "print('test_images_subsampled.shape: ', test_images_subsampled.shape)\n",
    "\n",
    "# Filter a subset of digits and a fixed number of samples\n",
    "digits = [0, 1]\n",
    "train_subset = 500\n",
    "test_subset = 200\n",
    "\n",
    "train_filter = np.isin(train_labels, digits)\n",
    "train_images = train_images_subsampled[train_filter][:train_subset]\n",
    "train_labels = train_labels[train_filter][:train_subset]\n",
    "\n",
    "test_filter = np.isin(test_labels, digits)\n",
    "test_images = test_images_subsampled[test_filter][:test_subset]\n",
    "test_labels = test_labels[test_filter][:test_subset]\n",
    "\n",
    "\n",
    "# Convert to JPEG embedding\n",
    "len_compressed_data = 20\n",
    "train_images_jpeg = np.zeros((train_images.shape[0], len_compressed_data))\n",
    "for i in range(len(train_images)):\n",
    "    train_images_jpeg[i] = get_jpeg_data(train_images[i], len_compressed_data)\n",
    "\n",
    "test_images_jpeg = np.zeros((test_images.shape[0], len_compressed_data))\n",
    "for i in range(len(test_images)):\n",
    "    test_images_jpeg[i] = get_jpeg_data(test_images[i], len_compressed_data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 23:29:24.133930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-29 23:29:24.502077: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 1s - loss: 69.4793 - accuracy: 0.5400 - val_loss: 38.2056 - val_accuracy: 0.6400 - 1s/epoch - 45ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 25.7839 - accuracy: 0.7175 - val_loss: 21.6387 - val_accuracy: 0.7300 - 68ms/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 16.7428 - accuracy: 0.7400 - val_loss: 14.1885 - val_accuracy: 0.7700 - 69ms/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 9.9171 - accuracy: 0.7925 - val_loss: 9.8334 - val_accuracy: 0.7800 - 70ms/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 5.6354 - accuracy: 0.7975 - val_loss: 10.1492 - val_accuracy: 0.7300 - 65ms/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 4.4937 - accuracy: 0.7525 - val_loss: 3.0513 - val_accuracy: 0.8100 - 61ms/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 2.0500 - accuracy: 0.7600 - val_loss: 2.3844 - val_accuracy: 0.6800 - 60ms/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 1.3282 - accuracy: 0.7500 - val_loss: 2.3875 - val_accuracy: 0.5900 - 61ms/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 1.0048 - accuracy: 0.7875 - val_loss: 1.8295 - val_accuracy: 0.7300 - 58ms/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 0.9872 - accuracy: 0.7950 - val_loss: 1.4612 - val_accuracy: 0.7300 - 61ms/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 0.7888 - accuracy: 0.7500 - val_loss: 1.7063 - val_accuracy: 0.7100 - 85ms/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 0.8332 - accuracy: 0.7775 - val_loss: 1.4316 - val_accuracy: 0.6900 - 79ms/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 0.7839 - accuracy: 0.7450 - val_loss: 1.5124 - val_accuracy: 0.7400 - 87ms/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 0.7435 - accuracy: 0.7850 - val_loss: 1.1712 - val_accuracy: 0.7700 - 88ms/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 0.9756 - accuracy: 0.7450 - val_loss: 1.4237 - val_accuracy: 0.6800 - 82ms/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 0.6869 - accuracy: 0.7675 - val_loss: 1.0860 - val_accuracy: 0.7000 - 77ms/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 0.8973 - accuracy: 0.7450 - val_loss: 1.0797 - val_accuracy: 0.8100 - 74ms/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 0.9933 - accuracy: 0.7450 - val_loss: 1.6652 - val_accuracy: 0.5300 - 70ms/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 0.7909 - accuracy: 0.7925 - val_loss: 1.1010 - val_accuracy: 0.7300 - 77ms/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 0.8509 - accuracy: 0.7550 - val_loss: 1.1010 - val_accuracy: 0.7900 - 83ms/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 0.8268 - accuracy: 0.7650 - val_loss: 1.3234 - val_accuracy: 0.7400 - 73ms/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 0.6506 - accuracy: 0.7775 - val_loss: 1.2764 - val_accuracy: 0.7700 - 72ms/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 0.9005 - accuracy: 0.7575 - val_loss: 1.5666 - val_accuracy: 0.7200 - 74ms/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 0.8688 - accuracy: 0.7575 - val_loss: 1.1524 - val_accuracy: 0.7600 - 82ms/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 0.7186 - accuracy: 0.7525 - val_loss: 1.5497 - val_accuracy: 0.7500 - 81ms/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 0.7422 - accuracy: 0.8000 - val_loss: 1.3433 - val_accuracy: 0.7400 - 73ms/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 0.7315 - accuracy: 0.7275 - val_loss: 1.1360 - val_accuracy: 0.7100 - 74ms/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 0.7531 - accuracy: 0.7675 - val_loss: 1.5081 - val_accuracy: 0.7400 - 72ms/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 1.2121 - accuracy: 0.7400 - val_loss: 1.7570 - val_accuracy: 0.7900 - 71ms/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 1.0063 - accuracy: 0.7775 - val_loss: 1.2748 - val_accuracy: 0.7800 - 74ms/epoch - 3ms/step\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1437 - accuracy: 0.7200\n",
      "\n",
      "\n",
      "Simple ANN Test accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "def Model1():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        keras.layers.Dense(30),\n",
    "        keras.layers.Dense(15),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "c_model = Model1()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images_jpeg,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data to compute accuracy\n",
    "loss, accuracy = c_model.evaluate(test_images_jpeg, test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'\\n\\nSimple ANN Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def reshape_x(input_array):\n",
    "    # Calculate the number of subarrays needed\n",
    "    num_subarrays = len(input_array) // 3 + (len(input_array) % 3 != 0)\n",
    "\n",
    "    # Split the array into subarrays of size 3\n",
    "    subarrays = [input_array[i * 3:(i + 1) * 3] for i in range(num_subarrays)]\n",
    "\n",
    "    # Check if the last subarray has fewer than 3 elements and pad with zeros if necessary\n",
    "    if len(subarrays[-1]) < 3:\n",
    "        subarrays[-1] = np.pad(subarrays[-1], (0, 3 - len(subarrays[-1])), mode='constant')\n",
    "        \n",
    "    return subarrays\n",
    "\n",
    "\n",
    "def cost(params, x, y, state_labels=None):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        float: loss value to be minimized\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    for i in range(len(x)):\n",
    "        f = qcircuit(params, x[i], dm_labels[y[i]])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(x)\n",
    "\n",
    "def test(params, x, y, state_labels=None):\n",
    "    \"\"\"\n",
    "    Tests on a given set of data.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        predicted (array([int]): predicted labels for test data\n",
    "        output_states (array[float]): output quantum states from the circuit\n",
    "    \"\"\"\n",
    "    fidelity_values = []\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fidel_function = lambda y: qcircuit(params, x[i], y)\n",
    "        fidelities = [fidel_function(dm) for dm in dm_labels]\n",
    "        best_fidel = np.argmax(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (array[float]): 1-d array of targets\n",
    "        y_predicted (array[float]): 1-d array of predictions\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        score (float): the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = np.array([label_0, label_1], requires_grad=False)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "\n",
    "    Args:\n",
    "        inputs (array[float]): input data\n",
    "        targets (array[float]): targets\n",
    "\n",
    "    Returns:\n",
    "        inputs (array[float]): one batch of input data of length `batch_size`\n",
    "        targets (array[float]): one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_q_classifier(num_layers = 10, stepsize = 0.1, momentum = 0.9, epochs = 10, batch_size = 32, n_qubits=1):\n",
    "\n",
    "    X_train = train_images_jpeg\n",
    "    y_train = train_labels\n",
    "    X_test = test_images_jpeg\n",
    "    y_test = test_labels\n",
    "    \n",
    "    \n",
    "\n",
    "    opt = NesterovMomentumOptimizer(stepsize=stepsize, momentum=momentum)\n",
    "\n",
    "    # initialize random weights\n",
    "    params = np.random.uniform(size=(num_layers, 2*n_qubits, X_train.shape[1]), requires_grad=True)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "    # save predictions with random weights for comparison\n",
    "    initial_predictions = predicted_test\n",
    "\n",
    "    loss = cost(params, X_test, y_test, state_labels)\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "            0, loss, accuracy_train, accuracy_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for it in range(epochs):\n",
    "        for Xbatch, ybatch in iterate_minibatches(X_train, y_train, batch_size=batch_size):\n",
    "            params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "\n",
    "        predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "        accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "        loss = cost(params, X_train, y_train, state_labels)\n",
    "\n",
    "        predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "        accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "        res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "        print(\n",
    "            \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "                *res\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return params, float(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=1)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for p in params: # Iterate num_layer times\n",
    "        w = p[0]\n",
    "        b = p[1]\n",
    "        encoding = w * x + b\n",
    "        encoding = reshape_x(encoding)\n",
    "        for encoding_sub in encoding:\n",
    "            qml.Rot(*encoding_sub, wires=0)\n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=1, stepsize=0.2, epochs=10)\n",
    "print(f'Accuracy of 1 qubit model with 1 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=3, stepsize=0.2, epochs=10)\n",
    "print(f'Accuracy of 1 qubit model with 3 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=10, stepsize=0.2, epochs=5)\n",
    "print(f'Accuracy of 1 qubit model with 10 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=2)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        w_0 = params[l, 0]\n",
    "        b_0 = params[l, 1]\n",
    "        w_1 = params[l, 2]\n",
    "        b_1 = params[l, 3]\n",
    "        \n",
    "        encoding_0 = w_0 * x + b_0\n",
    "        encoding_0 = reshape_x(encoding_0)\n",
    "        \n",
    "        encoding_1 = w_1 * x + b_1\n",
    "        encoding_1 = reshape_x(encoding_1)\n",
    "        \n",
    "        for i in range(len(encoding_0)):\n",
    "            qml.Rot(*(encoding_0[i]), wires=0)\n",
    "            qml.Rot(*(encoding_1[i]), wires=1)\n",
    "        \n",
    "        qml.CZ([0, 1]) \n",
    "    \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.264911 | Train accuracy: 0.494000 | Test Accuracy: 0.525000\n",
      "Epoch:  1 | Loss: 0.354581 | Train accuracy: 0.410000 | Test accuracy: 0.360000\n",
      "Epoch:  2 | Loss: 0.303229 | Train accuracy: 0.510000 | Test accuracy: 0.435000\n",
      "Epoch:  3 | Loss: 0.292774 | Train accuracy: 0.498000 | Test accuracy: 0.500000\n",
      "Epoch:  4 | Loss: 0.317100 | Train accuracy: 0.492000 | Test accuracy: 0.460000\n",
      "Epoch:  5 | Loss: 0.288755 | Train accuracy: 0.478000 | Test accuracy: 0.470000\n",
      "Accuracy of 2 qubit model with 5 layer: 0.47\n",
      "CPU times: user 11min 21s, sys: 842 ms, total: 11min 22s\n",
      "Wall time: 12min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5, n_qubits=2)\n",
    "print(f'Accuracy of 2 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=4)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        \n",
    "        w_0 = params[l, 0]\n",
    "        b_0 = params[l, 1]\n",
    "        w_1 = params[l, 2]\n",
    "        b_1 = params[l, 3]\n",
    "        w_2 = params[l, 4]\n",
    "        b_2 = params[l, 5]\n",
    "        w_3 = params[l, 6]\n",
    "        b_3 = params[l, 7]\n",
    "        \n",
    "        \n",
    "        encoding_0 = w_0 * x + b_0\n",
    "        encoding_0 = reshape_x(encoding_0)\n",
    "        \n",
    "        encoding_1 = w_1 * x + b_1\n",
    "        encoding_1 = reshape_x(encoding_1)\n",
    "        \n",
    "        encoding_2 = w_2 * x + b_2\n",
    "        encoding_2 = reshape_x(encoding_2)\n",
    "        \n",
    "        encoding_3 = w_3 * x + b_3\n",
    "        encoding_3 = reshape_x(encoding_3)\n",
    "        \n",
    "        for i in range(len(encoding_0)):\n",
    "            qml.Rot(*(encoding_0[i]), wires=0)\n",
    "            qml.Rot(*(encoding_1[i]), wires=1)\n",
    "            qml.Rot(*(encoding_2[i]), wires=2)\n",
    "            qml.Rot(*(encoding_3[i]), wires=3)\n",
    "        \n",
    "        if l % 2 != 0:\n",
    "            qml.CZ([0, 1])\n",
    "            qml.CZ([2, 3])\n",
    "        else:\n",
    "            qml.CZ([1, 2])\n",
    "            qml.CZ([0, 3]) \n",
    "    \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=1, stepsize=0.2, epochs=10, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 1 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=3, stepsize=0.2, epochs=10, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 3 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.342265 | Train accuracy: 0.468000 | Test Accuracy: 0.445000\n",
      "Epoch:  1 | Loss: 0.285448 | Train accuracy: 0.536000 | Test accuracy: 0.540000\n",
      "Epoch:  2 | Loss: 0.290732 | Train accuracy: 0.498000 | Test accuracy: 0.490000\n",
      "Epoch:  3 | Loss: 0.307412 | Train accuracy: 0.492000 | Test accuracy: 0.455000\n",
      "Epoch:  4 | Loss: 0.297959 | Train accuracy: 0.528000 | Test accuracy: 0.510000\n",
      "Epoch:  5 | Loss: 0.301921 | Train accuracy: 0.494000 | Test accuracy: 0.370000\n",
      "Accuracy of 4 qubit model with 5 layer: 0.37\n",
      "CPU times: user 11min 26s, sys: 192 ms, total: 11min 26s\n",
      "Wall time: 12min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 416,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
