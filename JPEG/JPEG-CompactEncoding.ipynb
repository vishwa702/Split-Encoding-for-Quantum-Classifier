{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dafef955-4c2c-a871-f1d8-3e0d306393b0"
   },
   "source": [
    "# Using the MNIST data compressed with JPEG method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e26372e-f1bd-b50f-0c1c-33a44306d1f7"
   },
   "source": [
    "#Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 00:51:30.069118: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-30 00:51:30.071662: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 00:51:30.108045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 00:51:30.108074: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 00:51:30.108089: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 00:51:30.114333: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 00:51:30.115311: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 00:51:30.897463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from pennylane import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images_subsampled.shape:  (60000, 16, 16)\n",
      "test_images_subsampled.shape:  (10000, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "def get_jpeg_data(img, out_length=50):\n",
    "  # Load the image\n",
    "\n",
    "  # Convert the image to YCrCb color space\n",
    "  # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "  # Define the desired size for the subsampled image\n",
    "  new_width = img.shape[0]//2  # Set to half of the original width\n",
    "  new_height = img.shape[1]//2  # Set to half of the original height\n",
    "\n",
    "  # Resize the image to the desired size for subsampling\n",
    "  subsampled_image = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "  # Perform JPEG encoding\n",
    "  retval, buf = cv2.imencode('.jpg', subsampled_image, [cv2.IMWRITE_JPEG_QUALITY, 10])\n",
    "\n",
    "  def find_matching_slice(byte_list, target_slice):\n",
    "      for i in range(len(byte_list) - len(target_slice) + 1):\n",
    "          if byte_list[i:i + len(target_slice)] == target_slice:\n",
    "              return i\n",
    "      return -1\n",
    "\n",
    "  byte_list = buf.tolist()\n",
    "\n",
    "  # Define the start and end sequences to search for\n",
    "  start_sequence = [0xFF, 0xDA]\n",
    "  end_sequence = [0xFF, 0xD9]\n",
    "\n",
    "  # Find the starting and ending indices\n",
    "  start_index = find_matching_slice(byte_list, start_sequence)\n",
    "  end_index = find_matching_slice(byte_list, end_sequence)\n",
    "\n",
    "  # Extract the data between start and end sequences\n",
    "  if start_index != -1 and end_index != -1:\n",
    "      extracted_data = byte_list[start_index + len(start_sequence):end_index]\n",
    "      # Convert the extracted data back to a NumPy array if needed\n",
    "      extracted_data_np = np.array(extracted_data, dtype=np.uint8)\n",
    "\n",
    "      # Pad to fixed size\n",
    "      if extracted_data_np.shape[0] < out_length:\n",
    "        pad_width = out_length - extracted_data_np.shape[0]\n",
    "        extracted_data_np = np.pad(extracted_data_np, (0, pad_width), mode='constant', constant_values=0)\n",
    "      if extracted_data_np.shape[0] > out_length:\n",
    "         extracted_data_np = extracted_data_np[:out_length]\n",
    "      # print(\"Extracted data:\", extracted_data_np)\n",
    "      # print(\"Data Length: \", len(extracted_data_np))\n",
    "  else:\n",
    "      print(\"Start and end sequences not found in the data.\")\n",
    "  return extracted_data_np\n",
    "\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Resize/subsample images \n",
    "sub_dim = 16\n",
    "\n",
    "train_images_subsampled = np.zeros((train_images.shape[0], sub_dim, sub_dim))\n",
    "test_images_subsampled = np.zeros((test_images.shape[0], sub_dim, sub_dim))\n",
    "\n",
    "for i in range(train_images.shape[0]):\n",
    "    train_images_subsampled[i] = cv2.resize(train_images[i], (sub_dim, sub_dim))\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_images_subsampled[i] = cv2.resize(test_images[i], (sub_dim, sub_dim))\n",
    "\n",
    "    \n",
    "print('train_images_subsampled.shape: ', train_images_subsampled.shape)\n",
    "print('test_images_subsampled.shape: ', test_images_subsampled.shape)\n",
    "\n",
    "# Filter a subset of digits and a fixed number of samples\n",
    "digits = [0, 1]\n",
    "train_subset = 500\n",
    "test_subset = 200\n",
    "\n",
    "train_filter = np.isin(train_labels, digits)\n",
    "train_images = train_images_subsampled[train_filter][:train_subset]\n",
    "train_labels = train_labels[train_filter][:train_subset]\n",
    "\n",
    "test_filter = np.isin(test_labels, digits)\n",
    "test_images = test_images_subsampled[test_filter][:test_subset]\n",
    "test_labels = test_labels[test_filter][:test_subset]\n",
    "\n",
    "\n",
    "# Convert to JPEG embedding\n",
    "len_compressed_data = 20\n",
    "train_images_jpeg = np.zeros((train_images.shape[0], len_compressed_data))\n",
    "for i in range(len(train_images)):\n",
    "    train_images_jpeg[i] = get_jpeg_data(train_images[i], len_compressed_data)\n",
    "\n",
    "test_images_jpeg = np.zeros((test_images.shape[0], len_compressed_data))\n",
    "for i in range(len(test_images)):\n",
    "    test_images_jpeg[i] = get_jpeg_data(test_images[i], len_compressed_data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 00:51:32.104509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 00:51:32.147670: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 1s - loss: 80.2220 - accuracy: 0.2375 - val_loss: 23.7518 - val_accuracy: 0.5400 - 533ms/epoch - 21ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 13.2368 - accuracy: 0.7350 - val_loss: 12.9365 - val_accuracy: 0.7300 - 63ms/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 8.4912 - accuracy: 0.8025 - val_loss: 10.6619 - val_accuracy: 0.7500 - 62ms/epoch - 2ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 7.2697 - accuracy: 0.7850 - val_loss: 8.9280 - val_accuracy: 0.7700 - 59ms/epoch - 2ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 5.2276 - accuracy: 0.8150 - val_loss: 7.1793 - val_accuracy: 0.7600 - 52ms/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 4.4739 - accuracy: 0.7750 - val_loss: 5.7513 - val_accuracy: 0.7500 - 63ms/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 3.4225 - accuracy: 0.7675 - val_loss: 5.9504 - val_accuracy: 0.7100 - 52ms/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 2.9878 - accuracy: 0.7675 - val_loss: 3.8150 - val_accuracy: 0.7200 - 51ms/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 2.2362 - accuracy: 0.7700 - val_loss: 3.2614 - val_accuracy: 0.7500 - 55ms/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 1.6248 - accuracy: 0.7600 - val_loss: 3.8631 - val_accuracy: 0.7000 - 53ms/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 2.1781 - accuracy: 0.7575 - val_loss: 2.2732 - val_accuracy: 0.7500 - 52ms/epoch - 2ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 1.2116 - accuracy: 0.7450 - val_loss: 1.8329 - val_accuracy: 0.7400 - 56ms/epoch - 2ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 1.3355 - accuracy: 0.7350 - val_loss: 2.8516 - val_accuracy: 0.7300 - 52ms/epoch - 2ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 1.0675 - accuracy: 0.7900 - val_loss: 1.5999 - val_accuracy: 0.7400 - 53ms/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 1.2656 - accuracy: 0.7275 - val_loss: 1.9129 - val_accuracy: 0.7500 - 52ms/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 1.2024 - accuracy: 0.7375 - val_loss: 1.7439 - val_accuracy: 0.7300 - 53ms/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 1.5682 - accuracy: 0.7475 - val_loss: 2.7146 - val_accuracy: 0.7100 - 52ms/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 0.9744 - accuracy: 0.7800 - val_loss: 1.7869 - val_accuracy: 0.7400 - 54ms/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 1.2515 - accuracy: 0.7400 - val_loss: 1.5494 - val_accuracy: 0.7700 - 56ms/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 1.0356 - accuracy: 0.7275 - val_loss: 2.5015 - val_accuracy: 0.6800 - 52ms/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 1.5428 - accuracy: 0.7750 - val_loss: 2.6039 - val_accuracy: 0.7600 - 57ms/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 1.3818 - accuracy: 0.7525 - val_loss: 1.7581 - val_accuracy: 0.8100 - 65ms/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 1.2707 - accuracy: 0.7500 - val_loss: 1.6548 - val_accuracy: 0.7700 - 62ms/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 0.9050 - accuracy: 0.7675 - val_loss: 1.4446 - val_accuracy: 0.8100 - 67ms/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 0.7418 - accuracy: 0.7700 - val_loss: 1.3894 - val_accuracy: 0.7800 - 57ms/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 0.7415 - accuracy: 0.7750 - val_loss: 1.2793 - val_accuracy: 0.7500 - 49ms/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 0.7074 - accuracy: 0.7675 - val_loss: 1.5835 - val_accuracy: 0.8100 - 51ms/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 1.0051 - accuracy: 0.7550 - val_loss: 1.9120 - val_accuracy: 0.8000 - 55ms/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 1.4435 - accuracy: 0.7625 - val_loss: 2.1803 - val_accuracy: 0.7400 - 54ms/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 1.1069 - accuracy: 0.7625 - val_loss: 1.8426 - val_accuracy: 0.7000 - 52ms/epoch - 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4144 - accuracy: 0.6850\n",
      "\n",
      "\n",
      "Simple ANN Test accuracy: 0.6850\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def Model1():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        keras.layers.Dense(30),\n",
    "        keras.layers.Dense(15),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "c_model = Model1()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images_jpeg,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data to compute accuracy\n",
    "loss, accuracy = c_model.evaluate(test_images_jpeg, test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'\\n\\nSimple ANN Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def reshape_x(input_array):\n",
    "    # Calculate the number of subarrays needed\n",
    "    num_subarrays = len(input_array) // 3 + (len(input_array) % 3 != 0)\n",
    "\n",
    "    # Split the array into subarrays of size 3\n",
    "    subarrays = [input_array[i * 3:(i + 1) * 3] for i in range(num_subarrays)]\n",
    "\n",
    "    # Check if the last subarray has fewer than 3 elements and pad with zeros if necessary\n",
    "    if len(subarrays[-1]) < 3:\n",
    "        subarrays[-1] = np.pad(subarrays[-1], (0, 3 - len(subarrays[-1])), mode='constant')\n",
    "        \n",
    "    return subarrays\n",
    "\n",
    "\n",
    "def cost(params, x, y, state_labels=None):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        float: loss value to be minimized\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    for i in range(len(x)):\n",
    "        f = qcircuit(params, x[i], dm_labels[y[i]])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(x)\n",
    "\n",
    "def test(params, x, y, state_labels=None):\n",
    "    \"\"\"\n",
    "    Tests on a given set of data.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        predicted (array([int]): predicted labels for test data\n",
    "        output_states (array[float]): output quantum states from the circuit\n",
    "    \"\"\"\n",
    "    fidelity_values = []\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fidel_function = lambda y: qcircuit(params, x[i], y)\n",
    "        fidelities = [fidel_function(dm) for dm in dm_labels]\n",
    "        best_fidel = np.argmax(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (array[float]): 1-d array of targets\n",
    "        y_predicted (array[float]): 1-d array of predictions\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        score (float): the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = np.array([label_0, label_1], requires_grad=False)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "\n",
    "    Args:\n",
    "        inputs (array[float]): input data\n",
    "        targets (array[float]): targets\n",
    "\n",
    "    Returns:\n",
    "        inputs (array[float]): one batch of input data of length `batch_size`\n",
    "        targets (array[float]): one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_q_classifier(num_layers = 10, stepsize = 0.1, momentum = 0.9, epochs = 10, batch_size = 32, n_qubits=1):\n",
    "\n",
    "    X_train = train_images_jpeg\n",
    "    y_train = train_labels\n",
    "    X_test = test_images_jpeg\n",
    "    y_test = test_labels\n",
    "    \n",
    "    \n",
    "\n",
    "    opt = NesterovMomentumOptimizer(stepsize=stepsize, momentum=momentum)\n",
    "\n",
    "    # initialize random weights\n",
    "    params = np.random.uniform(size=(num_layers, 2*n_qubits, X_train.shape[1]), requires_grad=True)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "    # save predictions with random weights for comparison\n",
    "    initial_predictions = predicted_test\n",
    "\n",
    "    loss = cost(params, X_test, y_test, state_labels)\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "            0, loss, accuracy_train, accuracy_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for it in range(epochs):\n",
    "        for Xbatch, ybatch in iterate_minibatches(X_train, y_train, batch_size=batch_size):\n",
    "            params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "\n",
    "        predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "        accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "        loss = cost(params, X_train, y_train, state_labels)\n",
    "\n",
    "        predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "        accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "        res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "        print(\n",
    "            \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "                *res\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return params, float(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        \n",
    "        w_0 = params[l, 0]\n",
    "        b_0 = params[l, 1, 0]\n",
    "        \n",
    "        \n",
    "        # Compact Encoding \n",
    "        for w, x in zip(reshape_x(w_0), reshape_x(x)):\n",
    "            encoding_0 = np.dot(w, x) + b_0\n",
    "            qml.Rot(encoding_0, encoding_0, encoding_0, wires=0)\n",
    "            \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.427853 | Train accuracy: 0.422000 | Test Accuracy: 0.345000\n",
      "Epoch:  1 | Loss: 0.312766 | Train accuracy: 0.546000 | Test accuracy: 0.455000\n",
      "Epoch:  2 | Loss: 0.274649 | Train accuracy: 0.620000 | Test accuracy: 0.695000\n",
      "Epoch:  3 | Loss: 0.350124 | Train accuracy: 0.488000 | Test accuracy: 0.465000\n",
      "Epoch:  4 | Loss: 0.287211 | Train accuracy: 0.548000 | Test accuracy: 0.465000\n",
      "Epoch:  5 | Loss: 0.328605 | Train accuracy: 0.508000 | Test accuracy: 0.505000\n",
      "Accuracy of 1 qubit model with 5 layer: 0.505\n",
      "CPU times: user 1min 57s, sys: 30.6 ms, total: 1min 57s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5)\n",
    "print(f'Accuracy of 1 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=2)\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        \n",
    "        w_0 = params[l, 0]\n",
    "        b_0 = params[l, 1, 0]\n",
    "        w_1 = params[l, 2]\n",
    "        b_1 = params[l, 3, 0]\n",
    "        \n",
    "        # Compact Encoding \n",
    "        for w, x in zip(reshape_x(w_0), reshape_x(x)):\n",
    "            encoding_0 = np.dot(w, x) + b_0\n",
    "            qml.Rot(encoding_0, encoding_0, encoding_0, wires=0)\n",
    "        \n",
    "        for w, x in zip(reshape_x(w_1), reshape_x(x)):\n",
    "            encoding_1 = np.dot(w, x) + b_1\n",
    "            qml.Rot(encoding_1, encoding_1, encoding_1, wires=0)\n",
    "            \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.300306 | Train accuracy: 0.526000 | Test Accuracy: 0.470000\n",
      "Epoch:  1 | Loss: 0.398670 | Train accuracy: 0.384000 | Test accuracy: 0.395000\n",
      "Epoch:  2 | Loss: 0.392303 | Train accuracy: 0.386000 | Test accuracy: 0.410000\n",
      "Epoch:  3 | Loss: 0.308709 | Train accuracy: 0.526000 | Test accuracy: 0.545000\n",
      "Epoch:  4 | Loss: 0.364614 | Train accuracy: 0.410000 | Test accuracy: 0.495000\n",
      "Epoch:  5 | Loss: 0.415796 | Train accuracy: 0.392000 | Test accuracy: 0.320000\n",
      "Accuracy of 2 qubit model with 5 layer: 0.32\n",
      "CPU times: user 2min 47s, sys: 92.6 ms, total: 2min 47s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5, n_qubits=2)\n",
    "print(f'Accuracy of 2 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=4)\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        \n",
    "        w_0 = params[l, 0]\n",
    "        b_0 = params[l, 1, 0]\n",
    "        w_1 = params[l, 2]\n",
    "        b_1 = params[l, 3, 0]\n",
    "        w_2 = params[l, 4]\n",
    "        b_2 = params[l, 5, 0]\n",
    "        w_3 = params[l, 6]\n",
    "        b_3 = params[l, 7, 0]\n",
    "        \n",
    "        # Compact Encoding \n",
    "        for w, x in zip(reshape_x(w_0), reshape_x(x)):\n",
    "            encoding_0 = np.dot(w, x) + b_0\n",
    "            qml.Rot(encoding_0, encoding_0, encoding_0, wires=0)\n",
    "        \n",
    "        for w, x in zip(reshape_x(w_1), reshape_x(x)):\n",
    "            encoding_1 = np.dot(w, x) + b_1\n",
    "            qml.Rot(encoding_1, encoding_1, encoding_1, wires=0)\n",
    "        \n",
    "        for w, x in zip(reshape_x(w_2), reshape_x(x)):\n",
    "            encoding_2 = np.dot(w, x) + b_2\n",
    "            qml.Rot(encoding_2, encoding_2, encoding_2, wires=0)\n",
    "        \n",
    "        for w, x in zip(reshape_x(w_3), reshape_x(x)):\n",
    "            encoding_3 = np.dot(w, x) + b_3\n",
    "            qml.Rot(encoding_3, encoding_3, encoding_3, wires=0)\n",
    "            \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.323262 | Train accuracy: 0.450000 | Test Accuracy: 0.390000\n",
      "Epoch:  1 | Loss: 0.444846 | Train accuracy: 0.384000 | Test accuracy: 0.390000\n",
      "Epoch:  2 | Loss: 0.300855 | Train accuracy: 0.570000 | Test accuracy: 0.615000\n",
      "Epoch:  3 | Loss: 0.286739 | Train accuracy: 0.552000 | Test accuracy: 0.535000\n",
      "Epoch:  4 | Loss: 0.368826 | Train accuracy: 0.458000 | Test accuracy: 0.360000\n",
      "Epoch:  5 | Loss: 0.261996 | Train accuracy: 0.648000 | Test accuracy: 0.690000\n",
      "Accuracy of 4 qubit model with 5 layer: 0.69\n",
      "CPU times: user 4min 40s, sys: 129 ms, total: 4min 40s\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 416,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
