{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dafef955-4c2c-a871-f1d8-3e0d306393b0"
   },
   "source": [
    "# Using the MNIST data compressed with JPEG method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e26372e-f1bd-b50f-0c1c-33a44306d1f7"
   },
   "source": [
    "#Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:59:31.139887: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-04 11:59:31.293690: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-04 11:59:31.830753: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 11:59:31.830818: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 11:59:31.831691: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 11:59:31.968679: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-04 11:59:31.976401: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 11:59:34.540590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from pennylane import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images_subsampled.shape:  (60000, 16, 16)\n",
      "test_images_subsampled.shape:  (10000, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "def get_jpeg_data(img, out_length=50):\n",
    "  # Load the image\n",
    "\n",
    "  # Convert the image to YCrCb color space\n",
    "  # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "  # Define the desired size for the subsampled image\n",
    "  new_width = img.shape[0]//2  # Set to half of the original width\n",
    "  new_height = img.shape[1]//2  # Set to half of the original height\n",
    "\n",
    "  # Resize the image to the desired size for subsampling\n",
    "  subsampled_image = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "  # Perform JPEG encoding\n",
    "  retval, buf = cv2.imencode('.jpg', subsampled_image, [cv2.IMWRITE_JPEG_QUALITY, 10])\n",
    "\n",
    "  def find_matching_slice(byte_list, target_slice):\n",
    "      for i in range(len(byte_list) - len(target_slice) + 1):\n",
    "          if byte_list[i:i + len(target_slice)] == target_slice:\n",
    "              return i\n",
    "      return -1\n",
    "\n",
    "  byte_list = buf.tolist()\n",
    "\n",
    "  # Define the start and end sequences to search for\n",
    "  start_sequence = [0xFF, 0xDA]\n",
    "  end_sequence = [0xFF, 0xD9]\n",
    "\n",
    "  # Find the starting and ending indices\n",
    "  start_index = find_matching_slice(byte_list, start_sequence)\n",
    "  end_index = find_matching_slice(byte_list, end_sequence)\n",
    "\n",
    "  # Extract the data between start and end sequences\n",
    "  if start_index != -1 and end_index != -1:\n",
    "      extracted_data = byte_list[start_index + len(start_sequence):end_index]\n",
    "      # Convert the extracted data back to a NumPy array if needed\n",
    "      extracted_data_np = np.array(extracted_data, dtype=np.uint8)\n",
    "\n",
    "      # Pad to fixed size\n",
    "      if extracted_data_np.shape[0] < out_length:\n",
    "        pad_width = out_length - extracted_data_np.shape[0]\n",
    "        extracted_data_np = np.pad(extracted_data_np, (0, pad_width), mode='constant', constant_values=0)\n",
    "      if extracted_data_np.shape[0] > out_length:\n",
    "         extracted_data_np = extracted_data_np[:out_length]\n",
    "      # print(\"Extracted data:\", extracted_data_np)\n",
    "      # print(\"Data Length: \", len(extracted_data_np))\n",
    "  else:\n",
    "      print(\"Start and end sequences not found in the data.\")\n",
    "  return extracted_data_np\n",
    "\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Resize/subsample images \n",
    "sub_dim = 16\n",
    "\n",
    "train_images_subsampled = np.zeros((train_images.shape[0], sub_dim, sub_dim))\n",
    "test_images_subsampled = np.zeros((test_images.shape[0], sub_dim, sub_dim))\n",
    "\n",
    "for i in range(train_images.shape[0]):\n",
    "    train_images_subsampled[i] = cv2.resize(train_images[i], (sub_dim, sub_dim))\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_images_subsampled[i] = cv2.resize(test_images[i], (sub_dim, sub_dim))\n",
    "\n",
    "    \n",
    "print('train_images_subsampled.shape: ', train_images_subsampled.shape)\n",
    "print('test_images_subsampled.shape: ', test_images_subsampled.shape)\n",
    "\n",
    "# Filter a subset of digits and a fixed number of samples\n",
    "digits = [0, 1]\n",
    "train_subset = 500\n",
    "test_subset = 200\n",
    "\n",
    "train_filter = np.isin(train_labels, digits)\n",
    "train_images = train_images_subsampled[train_filter][:train_subset]\n",
    "train_labels = train_labels[train_filter][:train_subset]\n",
    "\n",
    "test_filter = np.isin(test_labels, digits)\n",
    "test_images = test_images_subsampled[test_filter][:test_subset]\n",
    "test_labels = test_labels[test_filter][:test_subset]\n",
    "\n",
    "\n",
    "# Convert to JPEG embedding\n",
    "len_compressed_data = 20\n",
    "train_images_jpeg = np.zeros((train_images.shape[0], len_compressed_data))\n",
    "for i in range(len(train_images)):\n",
    "    train_images_jpeg[i] = get_jpeg_data(train_images[i], len_compressed_data)\n",
    "\n",
    "test_images_jpeg = np.zeros((test_images.shape[0], len_compressed_data))\n",
    "for i in range(len(test_images)):\n",
    "    test_images_jpeg[i] = get_jpeg_data(test_images[i], len_compressed_data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:59:40.394358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-04 11:59:41.095933: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 1s - loss: 79.7771 - accuracy: 0.3075 - val_loss: 23.9504 - val_accuracy: 0.5800 - 1s/epoch - 47ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 12.7684 - accuracy: 0.6125 - val_loss: 5.9886 - val_accuracy: 0.7100 - 69ms/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 4.7566 - accuracy: 0.7775 - val_loss: 2.9618 - val_accuracy: 0.7900 - 64ms/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 2.8056 - accuracy: 0.7625 - val_loss: 2.0012 - val_accuracy: 0.8000 - 63ms/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 1.7771 - accuracy: 0.7700 - val_loss: 1.8260 - val_accuracy: 0.7400 - 59ms/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 1.5097 - accuracy: 0.7525 - val_loss: 1.4492 - val_accuracy: 0.7900 - 62ms/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 1.1744 - accuracy: 0.7500 - val_loss: 1.1059 - val_accuracy: 0.7900 - 59ms/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 1.0102 - accuracy: 0.7725 - val_loss: 0.9289 - val_accuracy: 0.8300 - 58ms/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 0.7756 - accuracy: 0.7725 - val_loss: 0.7935 - val_accuracy: 0.8300 - 65ms/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 0.7006 - accuracy: 0.7975 - val_loss: 0.8317 - val_accuracy: 0.7200 - 72ms/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 0.6473 - accuracy: 0.7875 - val_loss: 0.5641 - val_accuracy: 0.8400 - 65ms/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 0.7958 - accuracy: 0.7375 - val_loss: 0.7102 - val_accuracy: 0.8000 - 64ms/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 0.7022 - accuracy: 0.7425 - val_loss: 0.9921 - val_accuracy: 0.7900 - 66ms/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 0.6178 - accuracy: 0.8025 - val_loss: 0.7901 - val_accuracy: 0.6200 - 71ms/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 0.6267 - accuracy: 0.7625 - val_loss: 0.7313 - val_accuracy: 0.7600 - 75ms/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 0.6750 - accuracy: 0.7475 - val_loss: 0.5752 - val_accuracy: 0.7900 - 75ms/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 0.5940 - accuracy: 0.7375 - val_loss: 0.5594 - val_accuracy: 0.7600 - 77ms/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 0.5169 - accuracy: 0.7900 - val_loss: 0.7711 - val_accuracy: 0.6200 - 80ms/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 0.5748 - accuracy: 0.7825 - val_loss: 0.6032 - val_accuracy: 0.7300 - 64ms/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 0.5079 - accuracy: 0.7625 - val_loss: 0.6209 - val_accuracy: 0.7800 - 59ms/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 0.6231 - accuracy: 0.7475 - val_loss: 0.6846 - val_accuracy: 0.7900 - 58ms/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 0.5666 - accuracy: 0.7450 - val_loss: 1.1728 - val_accuracy: 0.7700 - 65ms/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 0.6172 - accuracy: 0.7825 - val_loss: 0.8402 - val_accuracy: 0.7600 - 66ms/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 0.5628 - accuracy: 0.7875 - val_loss: 0.6939 - val_accuracy: 0.7700 - 60ms/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 0.5709 - accuracy: 0.7650 - val_loss: 0.8899 - val_accuracy: 0.7000 - 64ms/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 0.7557 - accuracy: 0.7600 - val_loss: 0.9276 - val_accuracy: 0.7900 - 64ms/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 0.5549 - accuracy: 0.7825 - val_loss: 0.5880 - val_accuracy: 0.7900 - 61ms/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 0.6930 - accuracy: 0.7525 - val_loss: 0.8466 - val_accuracy: 0.7800 - 69ms/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 0.5324 - accuracy: 0.7875 - val_loss: 0.7457 - val_accuracy: 0.7800 - 64ms/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 0.5483 - accuracy: 0.7925 - val_loss: 0.6422 - val_accuracy: 0.7900 - 74ms/epoch - 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8350\n",
      "\n",
      "\n",
      "Simple ANN Test accuracy: 0.8350\n",
      "CPU times: user 3.66 s, sys: 1.99 s, total: 5.65 s\n",
      "Wall time: 5.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def Model1():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        keras.layers.Dense(30),\n",
    "        keras.layers.Dense(15),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "c_model = Model1()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images_jpeg,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data to compute accuracy\n",
    "loss, accuracy = c_model.evaluate(test_images_jpeg, test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'\\n\\nSimple ANN Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def reshape_x(input_array):\n",
    "    # Calculate the number of subarrays needed\n",
    "    num_subarrays = len(input_array) // 3 + (len(input_array) % 3 != 0)\n",
    "\n",
    "    # Split the array into subarrays of size 3\n",
    "    subarrays = [input_array[i * 3:(i + 1) * 3] for i in range(num_subarrays)]\n",
    "\n",
    "    # Check if the last subarray has fewer than 3 elements and pad with zeros if necessary\n",
    "    if len(subarrays[-1]) < 3:\n",
    "        subarrays[-1] = np.pad(subarrays[-1], (0, 3 - len(subarrays[-1])), mode='constant')\n",
    "        \n",
    "    return subarrays\n",
    "\n",
    "\n",
    "def cost(params, x, y, state_labels=None):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        float: loss value to be minimized\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    for i in range(len(x)):\n",
    "        f = qcircuit(params, x[i], dm_labels[y[i]])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(x)\n",
    "\n",
    "def test(params, x, y, state_labels=None):\n",
    "    \"\"\"\n",
    "    Tests on a given set of data.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        predicted (array([int]): predicted labels for test data\n",
    "        output_states (array[float]): output quantum states from the circuit\n",
    "    \"\"\"\n",
    "    fidelity_values = []\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fidel_function = lambda y: qcircuit(params, x[i], y)\n",
    "        fidelities = [fidel_function(dm) for dm in dm_labels]\n",
    "        best_fidel = np.argmax(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (array[float]): 1-d array of targets\n",
    "        y_predicted (array[float]): 1-d array of predictions\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        score (float): the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = np.array([label_0, label_1], requires_grad=False)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "\n",
    "    Args:\n",
    "        inputs (array[float]): input data\n",
    "        targets (array[float]): targets\n",
    "\n",
    "    Returns:\n",
    "        inputs (array[float]): one batch of input data of length `batch_size`\n",
    "        targets (array[float]): one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_q_classifier(num_layers = 10, stepsize = 0.1, momentum = 0.9, epochs = 10, batch_size = 32, n_qubits=1):\n",
    "\n",
    "    X_train = train_images_jpeg\n",
    "    y_train = train_labels\n",
    "    X_test = test_images_jpeg\n",
    "    y_test = test_labels\n",
    "    \n",
    "    \n",
    "\n",
    "    opt = NesterovMomentumOptimizer(stepsize=stepsize, momentum=momentum)\n",
    "\n",
    "    # initialize random weights\n",
    "    params = np.random.uniform(size=(num_layers, 2*n_qubits, X_train.shape[1]), requires_grad=True)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "    # save predictions with random weights for comparison\n",
    "    initial_predictions = predicted_test\n",
    "\n",
    "    loss = cost(params, X_test, y_test, state_labels)\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "            0, loss, accuracy_train, accuracy_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for it in range(epochs):\n",
    "        for Xbatch, ybatch in iterate_minibatches(X_train, y_train, batch_size=batch_size):\n",
    "            params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "\n",
    "        predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "        accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "        loss = cost(params, X_train, y_train, state_labels)\n",
    "\n",
    "        predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "        accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "        res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "        print(\n",
    "            \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "                *res\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return params, float(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/QC/604/quantum-image-classifier/.venv/lib/python3.10/site-packages/pennylane_lightning/lightning_gpu/lightning_gpu.py:76: UserWarning: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "  warn(str(e), UserWarning)\n",
      "/home/vishwa/QC/604/quantum-image-classifier/.venv/lib/python3.10/site-packages/pennylane_lightning/lightning_gpu/lightning_gpu.py:958: UserWarning: \n",
      "                \"Pre-compiled binaries for lightning.gpu are not available. Falling back to \"\n",
      "                \"using the Python-based default.qubit implementation. To manually compile from \"\n",
      "                \"source, follow the instructions at \"\n",
      "                \"https://pennylane-lightning.readthedocs.io/en/latest/installation.html.\",\n",
      "            \n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=2)\n",
    "# Install any pennylane-plugin to run on some particular backend\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(x) != len(params[0, 0]):\n",
    "        print(f'shape mismatch! x: {x.shape} | w: {params[0][0].shape}')\n",
    "    \n",
    "    # If input has less than 3 dimensions, use a single qubit \n",
    "    if len(x) <= 3:\n",
    "        for p in params: # Iterate num_layer times\n",
    "            w = p[0]\n",
    "            b = p[1]\n",
    "            encoding = w * x + b\n",
    "            encoding = reshape_x(encoding)\n",
    "            for encoding_sub in encoding:\n",
    "                qml.Rot(*encoding_sub, wires=0)\n",
    "        return qml.expval(qml.Hermitian(y, wires=[0]))\n",
    "    \n",
    "    \n",
    "    n_qubits = len(dev.wires)\n",
    "    for l in range(params.shape[0] // 2): # Iterate num_layers / 2 times\n",
    "        w = params[l, 0]\n",
    "        b = params[l, 1]\n",
    "        \n",
    "        encoding = w * x + b\n",
    "        encoding = reshape_x(encoding)\n",
    "        \n",
    "        # Pad encoding if needed    \n",
    "        for _ in range( math.ceil(len(encoding)/n_qubits)*n_qubits - len(encoding)):\n",
    "            encoding.append(np.array([0, 0, 0]))\n",
    "        \n",
    "        for i in range(0, len(encoding), n_qubits):\n",
    "            for offset in range(n_qubits):\n",
    "                qml.Rot(*(encoding[i+offset]), wires=offset)\n",
    "                # qml.Rot(*(encoding[i+1]), wires=1)\n",
    "        \n",
    "        qml.CZ([0, 1]) \n",
    "    \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=1, stepsize=0.2, epochs=10)\n",
    "print(f'Accuracy of 2 qubit model with 1 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=3, stepsize=0.2, epochs=10)\n",
    "print(f'Accuracy of 2 qubit model with 3 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.317253 | Train accuracy: 0.496000 | Test Accuracy: 0.500000\n",
      "Epoch:  1 | Loss: 0.313666 | Train accuracy: 0.482000 | Test accuracy: 0.500000\n",
      "Epoch:  2 | Loss: 0.283276 | Train accuracy: 0.536000 | Test accuracy: 0.540000\n",
      "Epoch:  3 | Loss: 0.309711 | Train accuracy: 0.492000 | Test accuracy: 0.450000\n",
      "Epoch:  4 | Loss: 0.278073 | Train accuracy: 0.532000 | Test accuracy: 0.535000\n",
      "Epoch:  5 | Loss: 0.329534 | Train accuracy: 0.434000 | Test accuracy: 0.360000\n",
      "Accuracy of 2 qubit model with 5 layer: 0.36\n",
      "CPU times: user 2min 57s, sys: 0 ns, total: 2min 57s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5)\n",
    "print(f'Accuracy of 2 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.343863 | Train accuracy: 0.482000 | Test Accuracy: 0.480000\n",
      "Epoch:  1 | Loss: 0.313515 | Train accuracy: 0.506000 | Test accuracy: 0.565000\n",
      "Epoch:  2 | Loss: 0.331410 | Train accuracy: 0.484000 | Test accuracy: 0.430000\n",
      "Epoch:  3 | Loss: 0.297354 | Train accuracy: 0.508000 | Test accuracy: 0.505000\n",
      "Epoch:  4 | Loss: 0.296745 | Train accuracy: 0.504000 | Test accuracy: 0.490000\n",
      "Epoch:  5 | Loss: 0.271793 | Train accuracy: 0.574000 | Test accuracy: 0.605000\n",
      "Accuracy of 2 qubit model with 10 layer: 0.605\n",
      "CPU times: user 7min 8s, sys: 523 ms, total: 7min 8s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=10, stepsize=0.2, epochs=5)\n",
    "print(f'Accuracy of 2 qubit model with 10 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=4)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    # If input has less than 3 dimensions, use a single qubit \n",
    "    if len(x) <= 3:\n",
    "        for p in params: # Iterate num_layer times\n",
    "            w = p[0]\n",
    "            b = p[1]\n",
    "            encoding = w * x + b\n",
    "            encoding = reshape_x(encoding)\n",
    "            for encoding_sub in encoding:\n",
    "                qml.Rot(*encoding_sub, wires=0)\n",
    "        return qml.expval(qml.Hermitian(y, wires=[0]))\n",
    "    \n",
    "    n_qubits = 4\n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        \n",
    "        w = params[l, 0]\n",
    "        b = params[l, 1]\n",
    "        \n",
    "        encoding = w * x + b\n",
    "        encoding = reshape_x(encoding)\n",
    "        \n",
    "        \n",
    "        # Pad encoding if needed    \n",
    "        for _ in range( math.ceil(len(encoding)/n_qubits)*n_qubits - len(encoding)):\n",
    "            encoding.append(np.array([0, 0, 0]))\n",
    "        \n",
    "        for i in range(0, len(encoding), n_qubits):\n",
    "            for offset in range(n_qubits):\n",
    "                qml.Rot(*(encoding[i+offset]), wires=offset)\n",
    "        \n",
    "        if l % 2 != 0:\n",
    "            qml.CZ([0, 1])\n",
    "            qml.CZ([2, 3])\n",
    "        else:\n",
    "            qml.CZ([1, 2])\n",
    "            qml.CZ([0, 3]) \n",
    "    \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=1, stepsize=0.2, epochs=10, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 1 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=3, stepsize=0.2, epochs=10, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 3 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.253296 | Train accuracy: 0.514000 | Test Accuracy: 0.550000\n",
      "Epoch:  1 | Loss: 0.266036 | Train accuracy: 0.478000 | Test accuracy: 0.420000\n",
      "Epoch:  2 | Loss: 0.263801 | Train accuracy: 0.504000 | Test accuracy: 0.585000\n",
      "Epoch:  3 | Loss: 0.267867 | Train accuracy: 0.494000 | Test accuracy: 0.585000\n",
      "Epoch:  4 | Loss: 0.303541 | Train accuracy: 0.480000 | Test accuracy: 0.450000\n",
      "Epoch:  5 | Loss: 0.267772 | Train accuracy: 0.504000 | Test accuracy: 0.570000\n",
      "Accuracy of 4 qubit model with 5 layer: 0.57\n",
      "CPU times: user 7min 55s, sys: 0 ns, total: 7min 55s\n",
      "Wall time: 8min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.271479 | Train accuracy: 0.476000 | Test Accuracy: 0.465000\n",
      "Epoch:  1 | Loss: 0.266376 | Train accuracy: 0.494000 | Test accuracy: 0.530000\n",
      "Epoch:  2 | Loss: 0.264168 | Train accuracy: 0.466000 | Test accuracy: 0.440000\n",
      "Epoch:  3 | Loss: 0.268443 | Train accuracy: 0.456000 | Test accuracy: 0.400000\n",
      "Epoch:  4 | Loss: 0.251820 | Train accuracy: 0.534000 | Test accuracy: 0.560000\n",
      "Epoch:  5 | Loss: 0.256340 | Train accuracy: 0.552000 | Test accuracy: 0.565000\n",
      "Accuracy of 2 qubit model with 10 layer: 0.565\n",
      "CPU times: user 15min, sys: 1.26 s, total: 15min 1s\n",
      "Wall time: 15min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=10, stepsize=0.2, epochs=5)\n",
    "print(f'Accuracy of 2 qubit model with 10 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 416,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
