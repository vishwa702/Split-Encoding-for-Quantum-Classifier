{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dafef955-4c2c-a871-f1d8-3e0d306393b0"
   },
   "source": [
    "# Using the MNIST data compressed with JPEG method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e26372e-f1bd-b50f-0c1c-33a44306d1f7"
   },
   "source": [
    "#Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images_subsampled.shape:  (60000, 16, 16)\n",
      "test_images_subsampled.shape:  (10000, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "def get_jpeg_data(img, out_length=50):\n",
    "  # Load the image\n",
    "\n",
    "  # Convert the image to YCrCb color space\n",
    "  # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "  # Define the desired size for the subsampled image\n",
    "  new_width = img.shape[0]//2  # Set to half of the original width\n",
    "  new_height = img.shape[1]//2  # Set to half of the original height\n",
    "\n",
    "  # Resize the image to the desired size for subsampling\n",
    "  subsampled_image = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "  # Perform JPEG encoding\n",
    "  retval, buf = cv2.imencode('.jpg', subsampled_image, [cv2.IMWRITE_JPEG_QUALITY, 10])\n",
    "\n",
    "  def find_matching_slice(byte_list, target_slice):\n",
    "      for i in range(len(byte_list) - len(target_slice) + 1):\n",
    "          if byte_list[i:i + len(target_slice)] == target_slice:\n",
    "              return i\n",
    "      return -1\n",
    "\n",
    "  byte_list = buf.tolist()\n",
    "\n",
    "  # Define the start and end sequences to search for\n",
    "  start_sequence = [0xFF, 0xDA]\n",
    "  end_sequence = [0xFF, 0xD9]\n",
    "\n",
    "  # Find the starting and ending indices\n",
    "  start_index = find_matching_slice(byte_list, start_sequence)\n",
    "  end_index = find_matching_slice(byte_list, end_sequence)\n",
    "\n",
    "  # Extract the data between start and end sequences\n",
    "  if start_index != -1 and end_index != -1:\n",
    "      extracted_data = byte_list[start_index + len(start_sequence):end_index]\n",
    "      # Convert the extracted data back to a NumPy array if needed\n",
    "      extracted_data_np = np.array(extracted_data, dtype=np.uint8)\n",
    "\n",
    "      # Pad to fixed size\n",
    "      if extracted_data_np.shape[0] < out_length:\n",
    "        pad_width = out_length - extracted_data_np.shape[0]\n",
    "        extracted_data_np = np.pad(extracted_data_np, (0, pad_width), mode='constant', constant_values=0)\n",
    "      if extracted_data_np.shape[0] > out_length:\n",
    "         extracted_data_np = extracted_data_np[:out_length]\n",
    "      # print(\"Extracted data:\", extracted_data_np)\n",
    "      # print(\"Data Length: \", len(extracted_data_np))\n",
    "  else:\n",
    "      print(\"Start and end sequences not found in the data.\")\n",
    "  return extracted_data_np\n",
    "\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Resize/subsample images \n",
    "sub_dim = 16\n",
    "\n",
    "train_images_subsampled = np.zeros((train_images.shape[0], sub_dim, sub_dim))\n",
    "test_images_subsampled = np.zeros((test_images.shape[0], sub_dim, sub_dim))\n",
    "\n",
    "for i in range(train_images.shape[0]):\n",
    "    train_images_subsampled[i] = cv2.resize(train_images[i], (sub_dim, sub_dim))\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_images_subsampled[i] = cv2.resize(test_images[i], (sub_dim, sub_dim))\n",
    "\n",
    "    \n",
    "print('train_images_subsampled.shape: ', train_images_subsampled.shape)\n",
    "print('test_images_subsampled.shape: ', test_images_subsampled.shape)\n",
    "\n",
    "# Filter a subset of digits and a fixed number of samples\n",
    "digits = [0, 1]\n",
    "train_subset = 500\n",
    "test_subset = 200\n",
    "\n",
    "train_filter = np.isin(train_labels, digits)\n",
    "train_images = train_images_subsampled[train_filter][:train_subset]\n",
    "train_labels = train_labels[train_filter][:train_subset]\n",
    "\n",
    "test_filter = np.isin(test_labels, digits)\n",
    "test_images = test_images_subsampled[test_filter][:test_subset]\n",
    "test_labels = test_labels[test_filter][:test_subset]\n",
    "\n",
    "\n",
    "# Convert to JPEG embedding\n",
    "len_compressed_data = 20\n",
    "train_images_jpeg = np.zeros((train_images.shape[0], len_compressed_data))\n",
    "for i in range(len(train_images)):\n",
    "    train_images_jpeg[i] = get_jpeg_data(train_images[i], len_compressed_data)\n",
    "\n",
    "test_images_jpeg = np.zeros((test_images.shape[0], len_compressed_data))\n",
    "for i in range(len(test_images)):\n",
    "    test_images_jpeg[i] = get_jpeg_data(test_images[i], len_compressed_data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 103.1033 - accuracy: 0.1675 - val_loss: 24.0133 - val_accuracy: 0.4500 - 447ms/epoch - 18ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 12.5159 - accuracy: 0.6975 - val_loss: 8.0183 - val_accuracy: 0.8100 - 78ms/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 6.5610 - accuracy: 0.7700 - val_loss: 6.1374 - val_accuracy: 0.8300 - 101ms/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 3.9036 - accuracy: 0.7600 - val_loss: 4.6672 - val_accuracy: 0.7700 - 86ms/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 2.3013 - accuracy: 0.7950 - val_loss: 4.4331 - val_accuracy: 0.7700 - 68ms/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 1.8890 - accuracy: 0.7675 - val_loss: 3.0886 - val_accuracy: 0.8000 - 71ms/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 2.1842 - accuracy: 0.7325 - val_loss: 5.9064 - val_accuracy: 0.6200 - 67ms/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 2.9506 - accuracy: 0.7450 - val_loss: 3.4465 - val_accuracy: 0.7600 - 59ms/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 1.5865 - accuracy: 0.7775 - val_loss: 2.5557 - val_accuracy: 0.7200 - 70ms/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 1.2261 - accuracy: 0.7675 - val_loss: 2.0624 - val_accuracy: 0.7600 - 67ms/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 1.0240 - accuracy: 0.7800 - val_loss: 1.8950 - val_accuracy: 0.7600 - 92ms/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 0.9257 - accuracy: 0.7625 - val_loss: 1.5907 - val_accuracy: 0.7500 - 70ms/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 0.8229 - accuracy: 0.7800 - val_loss: 1.5723 - val_accuracy: 0.7100 - 50ms/epoch - 2ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 0.9418 - accuracy: 0.7225 - val_loss: 2.2600 - val_accuracy: 0.7700 - 52ms/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 1.1161 - accuracy: 0.7550 - val_loss: 1.5654 - val_accuracy: 0.7200 - 49ms/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 0.8247 - accuracy: 0.7625 - val_loss: 1.6413 - val_accuracy: 0.7300 - 49ms/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 1.2976 - accuracy: 0.7175 - val_loss: 1.0586 - val_accuracy: 0.7400 - 48ms/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 1.0886 - accuracy: 0.7400 - val_loss: 1.6608 - val_accuracy: 0.7600 - 52ms/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 1.2267 - accuracy: 0.7275 - val_loss: 2.4051 - val_accuracy: 0.7300 - 55ms/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 1.5330 - accuracy: 0.7725 - val_loss: 1.2705 - val_accuracy: 0.7100 - 57ms/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 0.7533 - accuracy: 0.7850 - val_loss: 0.9737 - val_accuracy: 0.7600 - 55ms/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 0.8094 - accuracy: 0.7750 - val_loss: 1.8355 - val_accuracy: 0.6600 - 54ms/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 1.2812 - accuracy: 0.7250 - val_loss: 3.1025 - val_accuracy: 0.7400 - 51ms/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 1.5354 - accuracy: 0.7775 - val_loss: 1.8588 - val_accuracy: 0.7300 - 50ms/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 0.9947 - accuracy: 0.7650 - val_loss: 2.7969 - val_accuracy: 0.5900 - 60ms/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 1.5201 - accuracy: 0.7350 - val_loss: 1.1214 - val_accuracy: 0.6900 - 51ms/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 1.2128 - accuracy: 0.7675 - val_loss: 1.2958 - val_accuracy: 0.6700 - 50ms/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 0.9544 - accuracy: 0.7150 - val_loss: 1.0527 - val_accuracy: 0.7200 - 58ms/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 0.6971 - accuracy: 0.7750 - val_loss: 1.1025 - val_accuracy: 0.7800 - 50ms/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 0.8711 - accuracy: 0.7675 - val_loss: 1.2040 - val_accuracy: 0.7800 - 50ms/epoch - 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3505 - accuracy: 0.7750\n",
      "\n",
      "\n",
      "Simple ANN Test accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "def Model1():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        keras.layers.Dense(30),\n",
    "        keras.layers.Dense(15),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "c_model = Model1()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images_jpeg,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data to compute accuracy\n",
    "loss, accuracy = c_model.evaluate(test_images_jpeg, test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'\\n\\nSimple ANN Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def reshape_x(input_array):\n",
    "    # Calculate the number of subarrays needed\n",
    "    num_subarrays = len(input_array) // 3 + (len(input_array) % 3 != 0)\n",
    "\n",
    "    # Split the array into subarrays of size 3\n",
    "    subarrays = [input_array[i * 3:(i + 1) * 3] for i in range(num_subarrays)]\n",
    "\n",
    "    # Check if the last subarray has fewer than 3 elements and pad with zeros if necessary\n",
    "    if len(subarrays[-1]) < 3:\n",
    "        subarrays[-1] = np.pad(subarrays[-1], (0, 3 - len(subarrays[-1])), mode='constant')\n",
    "        \n",
    "    return subarrays\n",
    "\n",
    "\n",
    "def cost(params, x, y, state_labels=None):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        float: loss value to be minimized\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    for i in range(len(x)):\n",
    "        f = qcircuit(params, x[i], dm_labels[y[i]])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(x)\n",
    "\n",
    "def test(params, x, y, state_labels=None):\n",
    "    \"\"\"\n",
    "    Tests on a given set of data.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        predicted (array([int]): predicted labels for test data\n",
    "        output_states (array[float]): output quantum states from the circuit\n",
    "    \"\"\"\n",
    "    fidelity_values = []\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fidel_function = lambda y: qcircuit(params, x[i], y)\n",
    "        fidelities = [fidel_function(dm) for dm in dm_labels]\n",
    "        best_fidel = np.argmax(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (array[float]): 1-d array of targets\n",
    "        y_predicted (array[float]): 1-d array of predictions\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        score (float): the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = np.array([label_0, label_1], requires_grad=False)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "\n",
    "    Args:\n",
    "        inputs (array[float]): input data\n",
    "        targets (array[float]): targets\n",
    "\n",
    "    Returns:\n",
    "        inputs (array[float]): one batch of input data of length `batch_size`\n",
    "        targets (array[float]): one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_q_classifier(num_layers = 10, stepsize = 0.1, momentum = 0.9, epochs = 10, batch_size = 32, n_qubits=1):\n",
    "\n",
    "    X_train = train_images_jpeg\n",
    "    y_train = train_labels\n",
    "    X_test = test_images_jpeg\n",
    "    y_test = test_labels\n",
    "    \n",
    "    \n",
    "\n",
    "    opt = NesterovMomentumOptimizer(stepsize=stepsize, momentum=momentum)\n",
    "\n",
    "    # initialize random weights\n",
    "    params = np.random.uniform(size=(num_layers, 2*n_qubits, X_train.shape[1]), requires_grad=True)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "    # save predictions with random weights for comparison\n",
    "    initial_predictions = predicted_test\n",
    "\n",
    "    loss = cost(params, X_test, y_test, state_labels)\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "            0, loss, accuracy_train, accuracy_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for it in range(epochs):\n",
    "        for Xbatch, ybatch in iterate_minibatches(X_train, y_train, batch_size=batch_size):\n",
    "            params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "\n",
    "        predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "        accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "        loss = cost(params, X_train, y_train, state_labels)\n",
    "\n",
    "        predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "        accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "        res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "        print(\n",
    "            \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "                *res\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return params, float(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    x = reshape_x(x)\n",
    "    for p in params: # Iterate num_layers times\n",
    "        w_0 = reshape_x(p)\n",
    "        \n",
    "        for x_sub in x:                 # Reupload data\n",
    "            qml.Rot(*x_sub, wires=0) \n",
    "        for w in w_0:                   # Qubit 1\n",
    "            qml.Rot(*w, wires=0)\n",
    "            \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[1;32m/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m initial_predictions \u001b[39m=\u001b[39m predicted_test\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m cost(params, X_test, y_test, state_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mEpoch: \u001b[39;49m\u001b[39m{:2d}\u001b[39;49;00m\u001b[39m | Cost: \u001b[39;49m\u001b[39m{:3f}\u001b[39;49;00m\u001b[39m | Train accuracy: \u001b[39;49m\u001b[39m{:3f}\u001b[39;49;00m\u001b[39m | Test Accuracy: \u001b[39;49m\u001b[39m{:3f}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39m0\u001b[39;49m, loss, accuracy_train, accuracy_test\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vishwa/QC/604/quantum-image-classifier/JPEG/JPEG-SimpleEncoding.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mfor\u001b[39;00m Xbatch, ybatch \u001b[39min\u001b[39;00m iterate_minibatches(X_train, y_train, batch_size\u001b[39m=\u001b[39mbatch_size):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5)\n",
    "print(f'Accuracy of 1 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=2)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "    This version follows the Pennylane demo and is a simplified implemenation. \n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    x = reshape_x(x)\n",
    "    for p in params: # Iterate num_layers times\n",
    "        w_0 = reshape_x(p[0])\n",
    "        w_1 = reshape_x(p[1])\n",
    "        \n",
    "        for x_sub in x:                 # Reupload data\n",
    "            qml.Rot(*x_sub, wires=0) \n",
    "            qml.Rot(*x_sub, wires=1)\n",
    "        for w in w_0:                   # Qubit 1\n",
    "            qml.Rot(*w, wires=0)\n",
    "        for w in w_1:                   # Qubit 2\n",
    "            qml.Rot(*w, wires=1)\n",
    "            \n",
    "        qml.CZ([0, 1]) \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.249803 | Train accuracy: 0.530000 | Test Accuracy: 0.620000\n",
      "Epoch:  1 | Loss: 0.234983 | Train accuracy: 0.654000 | Test accuracy: 0.615000\n",
      "Epoch:  2 | Loss: 0.237263 | Train accuracy: 0.620000 | Test accuracy: 0.675000\n",
      "Epoch:  3 | Loss: 0.224249 | Train accuracy: 0.648000 | Test accuracy: 0.645000\n",
      "Epoch:  4 | Loss: 0.219241 | Train accuracy: 0.644000 | Test accuracy: 0.650000\n",
      "Epoch:  5 | Loss: 0.239275 | Train accuracy: 0.614000 | Test accuracy: 0.700000\n",
      "Accuracy of 2 qubit model with 5 layer: 0.7\n",
      "CPU times: user 22min 49s, sys: 4.14 s, total: 22min 54s\n",
      "Wall time: 22min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5)\n",
    "print(f'Accuracy of 2 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=4)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y): #basic encoding\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "    This version follows the description of the paper to \"incorporate data and processing of angles in a single step\"\n",
    "    \n",
    "    Args:\n",
    "        params (array[float]): array of parameters of dim ( num_layers, 2, ceil(len(x)/3)*3 ) \n",
    "        x (array[float]): single input vector \n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    x = reshape_x(x)\n",
    "    \n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        \n",
    "        w_0 = params[l, 0]\n",
    "        w_1 = params[l, 1]\n",
    "        w_2 = params[l, 2]\n",
    "        w_3 = params[l, 3]\n",
    "        \n",
    "        encoding_0 = reshape_x(w_0)\n",
    "        encoding_1 = reshape_x(w_1)\n",
    "        encoding_2 = reshape_x(w_2)\n",
    "        encoding_3 = reshape_x(w_3)\n",
    "        \n",
    "        # Encode Data\n",
    "        for x_sub in x:\n",
    "            qml.Rot(*x_sub, wires=0)\n",
    "            qml.Rot(*x_sub, wires=1)\n",
    "            qml.Rot(*x_sub, wires=2)\n",
    "            qml.Rot(*x_sub, wires=3)\n",
    "        \n",
    "        # Parameter rotation\n",
    "        for i in range(len(encoding_0)):\n",
    "            qml.Rot(*(encoding_0[i]), wires=0)\n",
    "            qml.Rot(*(encoding_1[i]), wires=1)\n",
    "            qml.Rot(*(encoding_2[i]), wires=2)\n",
    "            qml.Rot(*(encoding_3[i]), wires=3)\n",
    "        \n",
    "        # Entanglement\n",
    "        if l % 2 != 0:\n",
    "            qml.CZ([0, 1])\n",
    "            qml.CZ([2, 3])\n",
    "        else:\n",
    "            qml.CZ([1, 2])\n",
    "            qml.CZ([0, 3])\n",
    "    \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=1, stepsize=0.2, epochs=10, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 1 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=3, stepsize=0.2, epochs=10, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 3 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.281485 | Train accuracy: 0.488000 | Test Accuracy: 0.445000\n",
      "Epoch:  1 | Loss: 0.215581 | Train accuracy: 0.656000 | Test accuracy: 0.670000\n",
      "Epoch:  2 | Loss: 0.218863 | Train accuracy: 0.634000 | Test accuracy: 0.655000\n",
      "Epoch:  3 | Loss: 0.216681 | Train accuracy: 0.652000 | Test accuracy: 0.675000\n",
      "Epoch:  4 | Loss: 0.199295 | Train accuracy: 0.688000 | Test accuracy: 0.695000\n",
      "Epoch:  5 | Loss: 0.196512 | Train accuracy: 0.706000 | Test accuracy: 0.710000\n",
      "Accuracy of 4 qubit model with 5 layer: 0.71\n",
      "CPU times: user 46min 12s, sys: 6.4 s, total: 46min 18s\n",
      "Wall time: 46min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params, accuracy = train_q_classifier(num_layers=5, stepsize=0.2, epochs=5, n_qubits=4)\n",
    "print(f'Accuracy of 4 qubit model with 5 layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 416,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
