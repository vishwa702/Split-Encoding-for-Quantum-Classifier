{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 20:11:35.673968: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-03 20:11:35.683827: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-03 20:11:35.770975: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-03 20:11:35.771035: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-03 20:11:35.771193: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-03 20:11:35.803884: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-03 20:11:35.805577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-03 20:11:36.875861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import make_classification\n",
    "import math\n",
    "\n",
    "# Quantum libraries\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer, QNGOptimizer, RotosolveOptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_x(input_array):\n",
    "    # Calculate the number of subarrays needed\n",
    "    num_subarrays = len(input_array) // 3 + (len(input_array) % 3 != 0)\n",
    "\n",
    "    # Split the array into subarrays of size 3\n",
    "    subarrays = [input_array[i * 3:(i + 1) * 3] for i in range(num_subarrays)]\n",
    "\n",
    "    # Check if the last subarray has fewer than 3 elements and pad with zeros if necessary\n",
    "    if len(subarrays[-1]) < 3:\n",
    "        subarrays[-1] = np.pad(subarrays[-1], (0, 3 - len(subarrays[-1])), mode='constant')\n",
    "        \n",
    "    return subarrays\n",
    "\n",
    "dev = qml.device(\"lightning.gpu\", wires=1)\n",
    "# Install any pennylane-plugin to run on some particular backend\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit_basic(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "    This version follows the Pennylane demo and is a simplified implemenation. \n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for p in params: # Iterate num_layers times\n",
    "        for x_sub in x:\n",
    "            qml.Rot(*x_sub, wires=0)\n",
    "        qml.Rot(*p, wires=0)\n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "    This version follows the description of the paper to \"incorporate data and processing of angles in a single step\"\n",
    "    \n",
    "    Args:\n",
    "        params (array[float]): array of parameters of dim ( num_layers, 2, ceil(len(x)/3)*3 ) \n",
    "        x (array[float]): single input vector \n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    for l in range(params.shape[0]): # Iterate num_layers times\n",
    "        w = params[l, 0]\n",
    "        b = params[l, 1]\n",
    "        \n",
    "        # print('x: ', x)\n",
    "        # print('x.shape: ', x.shape)\n",
    "        # print('w.shape: ', w.shape)\n",
    "        # print('b.shape: ', b.shape)\n",
    "        \n",
    "        weighted_sum = w * x + b\n",
    "        \n",
    "        weighted_sum = reshape_x(weighted_sum)\n",
    "        \n",
    "        for x_sub in weighted_sum:\n",
    "            qml.Rot(*x_sub, wires=0)\n",
    "    \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n",
    "\n",
    "\n",
    "def cost(params, x, y, state_labels=None):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        float: loss value to be minimized\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    for i in range(len(x)):\n",
    "        f = qcircuit(params, x[i], dm_labels[y[i]])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions for testing and creating batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(params, x, y, state_labels=None):\n",
    "    \"\"\"\n",
    "    Tests on a given set of data.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        predicted (array([int]): predicted labels for test data\n",
    "        output_states (array[float]): output quantum states from the circuit\n",
    "    \"\"\"\n",
    "    fidelity_values = []\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fidel_function = lambda y: qcircuit(params, x[i], y)\n",
    "        fidelities = [fidel_function(dm) for dm in dm_labels]\n",
    "        best_fidel = np.argmax(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (array[float]): 1-d array of targets\n",
    "        y_predicted (array[float]): 1-d array of predictions\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        score (float): the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "\n",
    "    Args:\n",
    "        inputs (array[float]): input data\n",
    "        targets (array[float]): targets\n",
    "\n",
    "    Returns:\n",
    "        inputs (array[float]): one batch of input data of length `batch_size`\n",
    "        targets (array[float]): one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output labels as quantum state vectors for binary classification\n",
    "\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "\n",
    "label_0 = [[1], [0]] # Digit Zero \n",
    "label_1 = [[0], [1]] # Digit One\n",
    "state_labels = np.array([label_0, label_1], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_q_classifier(n_samples = 500, n_features = 6, n_informative = 2, n_classes = 2, \n",
    "                num_layers = 10, learning_rate = 0.6, epochs = 10, batch_size = 32):\n",
    "    \n",
    "    # n_samples = 500\n",
    "    # n_features = 6\n",
    "    # n_informative = 2\n",
    "    # n_redundant = 4\n",
    "    # n_classes = 2\n",
    "\n",
    "    # Create a synthetic dataset with 2 classes\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=n_informative,\n",
    "        n_redundant=(n_features - n_informative),\n",
    "        n_classes=n_classes,\n",
    "        class_sep=2.,\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    # X = np.array(X)\n",
    "    # y = np.array(y)\n",
    "\n",
    "    # set training and test data\n",
    "    split = int(0.8 * n_samples)\n",
    "    X_train = X[:split, :]\n",
    "    y_train = y[:split]\n",
    "    X_test = X[split:, :]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    # Train using Adam optimizer and evaluate the classifier\n",
    "    # num_layers = 10\n",
    "    # learning_rate = 0.6\n",
    "    # epochs = 10\n",
    "    # batch_size = 32\n",
    "\n",
    "    opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "    # opt = RotosolveOptimizer()\n",
    "\n",
    "    # initialize random weights\n",
    "    params = np.random.uniform(size=(num_layers, 2, n_features), requires_grad=True)\n",
    "\n",
    "    label_0 = [[1], [0]] # Digit Zero \n",
    "    label_1 = [[0], [1]] # Digit One\n",
    "    state_labels = np.array([label_0, label_1], requires_grad=False)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "    # save predictions with random weights for comparison\n",
    "    initial_predictions = predicted_test\n",
    "\n",
    "    loss = cost(params, X_test, y_test, state_labels)\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "            0, loss, accuracy_train, accuracy_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for it in range(epochs):\n",
    "        for Xbatch, ybatch in iterate_minibatches(X_train, y_train, batch_size=batch_size):\n",
    "            params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "\n",
    "        predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "        accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "        loss = cost(params, X_train, y_train, state_labels)\n",
    "\n",
    "        predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "        accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "        res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "        print(\n",
    "            \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "                *res\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return float(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.277634 | Train accuracy: 0.585000 | Test Accuracy: 0.570000\n",
      "Epoch:  1 | Loss: 0.321084 | Train accuracy: 0.525000 | Test accuracy: 0.560000\n",
      "Epoch:  2 | Loss: 0.326920 | Train accuracy: 0.487500 | Test accuracy: 0.540000\n",
      "Epoch:  3 | Loss: 0.316163 | Train accuracy: 0.547500 | Test accuracy: 0.620000\n",
      "Epoch:  4 | Loss: 0.307821 | Train accuracy: 0.540000 | Test accuracy: 0.470000\n",
      "Epoch:  5 | Loss: 0.306118 | Train accuracy: 0.522500 | Test accuracy: 0.490000\n",
      "Epoch:  6 | Loss: 0.351159 | Train accuracy: 0.500000 | Test accuracy: 0.470000\n",
      "Epoch:  7 | Loss: 0.330241 | Train accuracy: 0.495000 | Test accuracy: 0.470000\n",
      "Epoch:  8 | Loss: 0.287979 | Train accuracy: 0.582500 | Test accuracy: 0.510000\n",
      "Epoch:  9 | Loss: 0.308528 | Train accuracy: 0.527500 | Test accuracy: 0.530000\n",
      "Epoch: 10 | Loss: 0.327481 | Train accuracy: 0.500000 | Test accuracy: 0.550000\n"
     ]
    }
   ],
   "source": [
    "_ = train_q_classifier(n_features=3, n_informative=3, num_layers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "This quantum classifier with a single qubit is found to be ineffective for input with dimension greater than 6. The accuracy is just around 50%.\n",
    "A multiqubit classifier should be tested next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
